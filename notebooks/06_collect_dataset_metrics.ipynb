{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regex patterns for parsing sparql queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_pattern = re.compile(r\"WHERE\\s+{\", re.I)\n",
    "no_where_pattern = re.compile(r\"SELECT\\s+.*?(?!\\bWHERE\\b)\\s*{\", re.I)\n",
    "\n",
    "# Regex pattern to match triples (subject predicate object .) and VALUES clauses\n",
    "triple_pattern = re.compile(r\"\"\"\n",
    "    (\\?\\w+|\\<[^>]*\\>|wd:[^\\s]+)\\s+   # Subject: variable, URI, or prefixed name\n",
    "    \\(?(\\?\\w+|\\<[^>]*\\>|wdt:[^\\s]+\\*?|p[\\w]*:[^\\s]+\\*?|rdfs:[^\\s]+|schema:[^\\s]+|\\w+:[^\\s]+\\*?\\s*\\/\\s*\\w+:[^\\s]+\\*?)\\)?\\s+  # Predicate: variable, URI, or prefixed name\n",
    "    (\\?\\w+|\\<[^>]*\\>|\"[^\"]*\"|wd:[^\\s]+|\\b\\d+|\\[\\])\\s*\\.?\\s*  # Object: variable, URI, literal, prefixed name, or number\n",
    "    \"\"\", re.VERBOSE)\n",
    "\n",
    "semicolon_pattern = re.compile(r\"\"\"\n",
    "    \\n\\s+(\\?\\w+|\\<[^>]*\\>|wd:[^\\s]+).*? # Subject\n",
    "    \\;\\s+ # semicolon\n",
    "    \\(?(\\?\\w+|\\<[^>]*\\>|wdt:[^\\s]+\\*?|p[\\w]*:[^\\s]+\\*?|rdfs:[^\\s]+|schema:[^\\s]+|\\w+:[^\\s]+\\*?\\s*\\/\\s*\\w+:[^\\s]+\\*?)\\)?\\s+ # Predicate\n",
    "    (\\?\\w+|\\<[^>]*\\>|\"[^\"]*\"|wd:[^\\s]+|\\b\\d+|\\[\\])\\s*\\.?\\s* # Object\n",
    "    \"\"\", re.VERBOSE)\n",
    "\n",
    "# VALUES clause with variable and values\n",
    "values_pattern = re.compile(r\"VALUES\\s+\\?\\w+\\s*{\\s*([^}]*)\\s*}\", re.I)\n",
    "\n",
    "# FILTER clause with expression inside parentheses\n",
    "filter_pattern = re.compile(r\"FILTER\\s*\\(\", re.I)\n",
    "\n",
    "# WITH clause with subquery inside brackets\n",
    "with_pattern = re.compile(r\"WITH\\s*\\{(.*?)\\}\\s*as\", re.I | re.DOTALL)\n",
    "\n",
    "# MINUS clause with subquery inside brackets\n",
    "minus_pattern = re.compile(r\"MINUS\\s*{\\s*([^}]*)\\s*}\", re.I | re.DOTALL)\n",
    "\n",
    "# OPTIONAL clause with subquery inside brackets\n",
    "optional_pattern = re.compile(r\"OPTIONAL\\s*{\\s*([^}]*)\\s*}\", re.I | re.DOTALL)\n",
    "\n",
    "# limit, group by, and order by regexes for counting clauses\n",
    "limit_pattern = re.compile(r\"LIMIT\\s*\\d+\", re.I)\n",
    "having_pattern = re.compile(r\"HAVING\\s*\\(\", re.I)\n",
    "group_by_pattern = re.compile(r\"GROUP\\s+BY\\s*\", re.I)\n",
    "order_by_pattern = re.compile(r\"ORDER\\s+BY\\s*\", re.I)\n",
    "\n",
    "# Extract variables and literals from FILTER expressions\n",
    "variable_pattern = re.compile(r'\\?\\w+')\n",
    "literal_pattern = re.compile(r'\"[^\"]*\"|\\b\\d+(?!\\w)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for parsing a sparql query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_where_content(sparql_query):\n",
    "    # Find the starting point of the WHERE clause\n",
    "    wheres = re.findall(where_pattern, sparql_query)\n",
    "    if len(wheres) == 0:\n",
    "        return None\n",
    "    \n",
    "    where_start = sparql_query.find(wheres[0])\n",
    "\n",
    "    # Initialize stack and index\n",
    "    stack = ['{']\n",
    "    index = where_start + len(wheres[0])\n",
    "    content_start = index\n",
    "\n",
    "    # Traverse the query to find the matching closing brace\n",
    "    while index < len(sparql_query):\n",
    "        char = sparql_query[index]\n",
    "        if char == '{':\n",
    "            stack.append('{')\n",
    "        elif char == '}':\n",
    "            if stack:\n",
    "                stack.pop()\n",
    "                if not stack:\n",
    "                    # Matching closing brace found\n",
    "                    content_end = index\n",
    "                    return sparql_query[content_start:content_end]\n",
    "        index += 1\n",
    "\n",
    "    return None\n",
    "\n",
    "def extract_filter_content(text):\n",
    "    filter_texts = []\n",
    "\n",
    "    # Find the starting point of the WHERE clause\n",
    "    filters = re.findall(filter_pattern, text)\n",
    "    for filter in filters:\n",
    "        filter_start = text.find(filter)\n",
    "        if filter_start == -1:\n",
    "            continue\n",
    "\n",
    "        # Initialize stack and index\n",
    "        stack = ['(']\n",
    "        index = filter_start + len(filter)\n",
    "        content_start = index\n",
    "\n",
    "        # Traverse the query to find the matching closing brace\n",
    "        while index < len(text):\n",
    "            char = text[index]\n",
    "            if char == '(':\n",
    "                stack.append('(')\n",
    "            elif char == ')':\n",
    "                if stack:\n",
    "                    stack.pop()\n",
    "                    if not stack:\n",
    "                        # Matching closing brace found\n",
    "                        content_end = index\n",
    "                        filter_texts.append(text[content_start:content_end])\n",
    "            index += 1\n",
    "\n",
    "    return filter_texts\n",
    "\n",
    "def parse_content(content):\n",
    "    clauses = 1 # if we're in this function, there's at least a SELECT or MINUS that we can assume\n",
    "    relations = set()\n",
    "    subjects = set()\n",
    "    predicates = set()\n",
    "    objects = set()\n",
    "    literals = set()\n",
    "\n",
    "    # Match triples in the content\n",
    "    for triple in triple_pattern.findall(content):\n",
    "        clauses += 1\n",
    "        relations.add(triple)\n",
    "        subjects.add(triple[0])\n",
    "        predicates.add(triple[1])\n",
    "        if triple[2].startswith('\"') and triple[2].endswith('\"'):\n",
    "            literals.add(triple[2])\n",
    "        elif triple[2].isdigit():\n",
    "            literals.add(triple[2])\n",
    "        else:\n",
    "            objects.add(triple[2])\n",
    "    \n",
    "    for semicolon in semicolon_pattern.findall(content):\n",
    "        clauses += 1\n",
    "        relations.add(semicolon)\n",
    "        subjects.add(semicolon[0])\n",
    "        predicates.add(semicolon[1])\n",
    "        if semicolon[2].startswith('\"') and semicolon[2].endswith('\"'):\n",
    "            literals.add(semicolon[2])\n",
    "        elif semicolon[2].isdigit():\n",
    "            literals.add(semicolon[2])\n",
    "        else:\n",
    "            objects.add(semicolon[2])\n",
    "\n",
    "    # Match VALUES clauses in the content\n",
    "    for values_match in values_pattern.findall(content):\n",
    "        clauses += 1\n",
    "        for value in values_match.split():\n",
    "            value = value.strip()\n",
    "            if value.startswith('wd:'):\n",
    "                objects.add(value)\n",
    "            elif value.startswith('\"') and value.endswith('\"'):\n",
    "                literals.add(value)\n",
    "            elif value.isdigit():\n",
    "                literals.add(value)\n",
    "\n",
    "    # Match FILTER clauses in the content\n",
    "    for filter_match in extract_filter_content(content):\n",
    "        clauses += 1\n",
    "        variables = variable_pattern.findall(filter_match)\n",
    "        for var in variables:\n",
    "            objects.add(var)\n",
    "\n",
    "        literal_matches = literal_pattern.findall(filter_match)\n",
    "        for lit in literal_matches:\n",
    "            literals.add(lit)\n",
    "\n",
    "    return clauses, relations, subjects, predicates, objects, literals\n",
    "\n",
    "def calculate_content(sparql_query):\n",
    "    total_clauses = 0\n",
    "    total_relations = set()\n",
    "    total_subjects = set()\n",
    "    total_predicates = set()\n",
    "    total_objects = set()\n",
    "    total_literals = set()\n",
    "\n",
    "    no_where = re.findall(no_where_pattern, sparql_query)\n",
    "    for nw in no_where:\n",
    "        sparql_query = sparql_query.replace(nw, f\"{nw[:-1]}WHERE {{\")\n",
    "    \n",
    "    sparql_query = re.sub(r';\\s+', '; ', sparql_query)\n",
    "\n",
    "    # Extract the content inside the WHERE clause\n",
    "    where_content = extract_where_content(sparql_query)\n",
    "    if where_content:\n",
    "        # if there's a subquery within the where content\n",
    "        subquery_content = extract_where_content(where_content)\n",
    "        if subquery_content:\n",
    "            # replace subquery content with nothing and calculate content for it\n",
    "            where_content = where_content.replace(subquery_content, '')\n",
    "            clauses, relations, subjects, predicates, objects, literals = parse_content(subquery_content)\n",
    "            total_clauses += clauses\n",
    "            total_relations.update(relations)\n",
    "            total_subjects.update(subjects)\n",
    "            total_predicates.update(predicates)\n",
    "            total_objects.update(objects)\n",
    "            total_literals.update(literals)\n",
    "\n",
    "        # Parse the main WHERE content\n",
    "        clauses, relations, subjects, predicates, objects, literals = parse_content(where_content)\n",
    "        total_clauses += clauses\n",
    "        total_relations.update(relations)\n",
    "        total_subjects.update(subjects)\n",
    "        total_predicates.update(predicates)\n",
    "        total_objects.update(objects)\n",
    "        total_literals.update(literals)\n",
    "\n",
    "        # Handle MINUS clauses\n",
    "        minus_queries = re.findall(minus_pattern, where_content)\n",
    "        for minus_query in minus_queries:\n",
    "            sub_clauses, sub_relations, sub_subjects, sub_predicates, sub_objects, sub_literals = parse_content(minus_query)\n",
    "            total_clauses += sub_clauses\n",
    "            total_relations.update(sub_relations)\n",
    "            total_subjects.update(sub_subjects)\n",
    "            total_predicates.update(sub_predicates)\n",
    "            total_objects.update(sub_objects)\n",
    "            total_literals.update(sub_literals)\n",
    "        \n",
    "        # Handle MINUS clauses\n",
    "        optional_queries = re.findall(optional_pattern, where_content)\n",
    "        for optional_query in optional_queries:\n",
    "            sub_clauses, sub_relations, sub_subjects, sub_predicates, sub_objects, sub_literals = parse_content(optional_query)\n",
    "            total_clauses += sub_clauses\n",
    "            total_relations.update(sub_relations)\n",
    "            total_subjects.update(sub_subjects)\n",
    "            total_predicates.update(sub_predicates)\n",
    "            total_objects.update(sub_objects)\n",
    "            total_literals.update(sub_literals)\n",
    "        \n",
    "    total_clauses += len(re.findall(limit_pattern, sparql_query))\n",
    "    total_clauses += len(re.findall(group_by_pattern, sparql_query))\n",
    "    total_clauses += len(re.findall(order_by_pattern, sparql_query))\n",
    "    total_clauses += len(re.findall(having_pattern, sparql_query))\n",
    "    return total_clauses, total_relations, total_subjects, total_predicates, total_objects, total_literals\n",
    "\n",
    "def regex_parse(sparql_query):\n",
    "    total_clauses = 0\n",
    "    total_relations = set()\n",
    "    total_subjects = set()\n",
    "    total_predicates = set()\n",
    "    total_objects = set()\n",
    "    total_literals = set()\n",
    "\n",
    "    # for each with clause\n",
    "    with_content = re.findall(with_pattern, sparql_query)\n",
    "    if with_content:\n",
    "        for w in with_content:\n",
    "            sparql_query = sparql_query.replace(w, '')\n",
    "            clauses, relations, subjects, predicates, objects, literals = calculate_content(w)\n",
    "            # print(calculate_content(w))\n",
    "            total_clauses += clauses\n",
    "            total_relations.update(relations)\n",
    "            total_subjects.update(subjects)\n",
    "            total_predicates.update(predicates)\n",
    "            total_objects.update(objects)\n",
    "            total_literals.update(literals)\n",
    "\n",
    "    clauses, relations, subjects, predicates, objects, literals = calculate_content(sparql_query)\n",
    "    # print(calculate_content(sparql_query))\n",
    "    total_clauses += clauses\n",
    "    total_relations.update(relations)\n",
    "    total_subjects.update(subjects)\n",
    "    total_predicates.update(predicates)\n",
    "    total_objects.update(objects)\n",
    "    total_literals.update(literals)\n",
    "    \n",
    "    # print(\"relations: \", total_relations)\n",
    "    # print(\"subjects: \", total_subjects)\n",
    "    # print(\"predicates: \", total_predicates)\n",
    "    # print(\"objects: \", total_objects)\n",
    "    # print(\"literals: \", total_literals)\n",
    "    return {\n",
    "        \"clauses\": total_clauses,\n",
    "        \"relations\": len(total_relations),\n",
    "        \"subjects\": len(total_subjects),\n",
    "        \"predicates\": len(total_predicates),\n",
    "        \"objects\": len(total_objects),\n",
    "        \"literals\": len(total_literals)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample queries with increasing complexity to validate helper functions\n",
    "We're counting the following features of a sparql query:\n",
    "- `clauses`: the total number of clauses in the sparql query, defined as:\n",
    "    - `SELECT ... WHERE { ... }` clauses\n",
    "    - triples (of the form `subject predicate object`)\n",
    "    - constraining subqueries (e.g. `MINUS { ... }`, `OPTIONAL { ... }`, `VALUES { ... }`, `FILTER(...)`)\n",
    "    - `GROUP BY`, `ORDER BY`, and `LIMIT` clauses\n",
    "- `relations`: the total number of triples (`subject predicate object`) in the sparql query\n",
    "- `subjects`: the total number of subjects (e.g. `?person`, `?item`, `?statement`) in the sparql query\n",
    "- `predicates`: the total number of predicates (e.g. `wdt:Pwww`, `p:Pxxx`, `pq:Pyyy`, `schema:zzz`) in the sparql query, *excluding wikibase*\n",
    "- `objects`: the total number of objects (e.g. `wd:Qaaa` or `?item`) in the sparql query\n",
    "- `literals`: the total number of literals (e.g. `\"string\"` or `123`) in the sparql query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clauses': 5, 'relations': 4, 'subjects': 3, 'predicates': 4, 'objects': 4, 'literals': 0}\n"
     ]
    }
   ],
   "source": [
    "# normal, simple query, no filters or minuses or values\n",
    "sq0 = '''\n",
    "#olympic gold medalist born in Maryland\n",
    "SELECT DISTINCT ?person ?personLabel WHERE {\n",
    "  ?person p:P1344 ?statement .\n",
    "  ?statement pq:P166 wd:Q15243387 .\n",
    "  ?person wdt:P19 ?birthplace .\n",
    "  ?birthplace wdt:P131* wd:Q1391\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" }\n",
    "}\n",
    "'''\n",
    "\n",
    "result = regex_parse(sq0)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clauses': 6, 'relations': 2, 'subjects': 1, 'predicates': 2, 'objects': 3, 'literals': 1}\n"
     ]
    }
   ],
   "source": [
    "# one step up â€” query with VALUES and FILTER\n",
    "sq1 = \"\"\"\n",
    "SELECT ?item ?itemLabel ?image WHERE {\n",
    "  ?item wdt:P31 wd:Q5 .\n",
    "  ?item wdt:P18 ?image .\n",
    "  VALUES ?item {wd:Q2104}\n",
    "  FILTER(CONTAINS(?image, \"1958\"))\n",
    "  SERVICE wikibase:label {\n",
    "    bd:serviceParam wikibase:language \"en,de,fr\".\n",
    "  }\n",
    "}\n",
    "LIMIT 1000\n",
    "\"\"\"\n",
    "\n",
    "result = regex_parse(sq1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clauses': 16, 'relations': 7, 'subjects': 2, 'predicates': 6, 'objects': 7, 'literals': 1}\n"
     ]
    }
   ],
   "source": [
    "sq2 = \"\"\"\n",
    "#Scientific authors known to Wikidata, who do not have an ORCID iD listed there\n",
    "SELECT ?author ?authorLabel ?instit ?institLabel ?count WHERE {\n",
    "  {\n",
    "    SELECT ?author (COUNT(DISTINCT ?publication) AS ?count) WHERE {\n",
    "      ?publication wdt:P31 wd:Q13442814 .\n",
    "      ?publication wdt:P50 ?author .\n",
    "      MINUS { ?author wdt:P496 [] } .\n",
    "      MINUS {\n",
    "        ?author wdt:P570 ?dod .\n",
    "        FILTER((YEAR(?dod)) < 2012)\n",
    "      } .\n",
    "    } GROUP BY ?author\n",
    "  } .\n",
    "  MINUS {\n",
    "    ?author p:P108/ps:P108 ?instit1;\n",
    "            p:P108/ps:P108 ?instit2 .\n",
    "    FILTER(!SAMETERM(?instit1, ?instit2))\n",
    "  } .\n",
    "  ?author wdt:P108 ?instit .\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" } .\n",
    "}\n",
    "ORDER BY DESC(?count)\n",
    "\"\"\"\n",
    "\n",
    "result = regex_parse(sq2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clauses': 8, 'relations': 3, 'subjects': 2, 'predicates': 3, 'objects': 2, 'literals': 1}\n"
     ]
    }
   ],
   "source": [
    "# query using WITH syntax\n",
    "sq3 = '''\n",
    "SELECT ?film ?filmLabel ?count\n",
    "WITH\n",
    "{\n",
    "  SELECT ?film (COUNT(?wikipage) AS ?count)\n",
    "  WHERE\n",
    "  {\n",
    "    hint:Query hint:optimizer \"None\" .\n",
    "    ?film wdt:P31 wd:Q11424 .\n",
    "    ?wikipage schema:about ?film .\n",
    "    ?wikipage schema:isPartOf/wikibase:wikiGroup \"wikipedia\" .\n",
    "  }\n",
    "  GROUP BY ?film HAVING (?count > 50)\n",
    "} AS %get_films\n",
    "WHERE\n",
    "{\n",
    "  INCLUDE %get_films\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" . }\n",
    "}\n",
    "ORDER BY DESC(?count)\n",
    "'''\n",
    "\n",
    "result = regex_parse(sq3)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clauses': 6, 'relations': 2, 'subjects': 1, 'predicates': 2, 'objects': 2, 'literals': 0}\n"
     ]
    }
   ],
   "source": [
    "# query using the `OPTIONAL` syntax\n",
    "sq4 = '''\n",
    "SELECT ?item ?area ?population ?pit\n",
    "WHERE\n",
    "{\n",
    "  ?item wdt:P31 wd:Q16739079 .\n",
    "  hint:Prior hint:rangeSafe true .\n",
    "  optional {  ?item p:P1082 [ ps:P1082 ?population; \n",
    "                              pq:P585 ?pit; \n",
    "                              wikibase:rank wikibase:PreferredRank ] \n",
    "           }\n",
    "  optional {  ?item wdt:P2046 ?a . \n",
    "              BIND(REPLACE(STR(?a),\"\\\\.\",\",\") AS ?area) \n",
    "           }\n",
    "}\n",
    "'''\n",
    "\n",
    "result = regex_parse(sq4)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clauses': 12, 'relations': 3, 'subjects': 2, 'predicates': 3, 'objects': 4, 'literals': 0}\n"
     ]
    }
   ],
   "source": [
    "# more complex query using a multi-subquery syntax\n",
    "sq5 = '''\n",
    "#defaultView:BarChart\n",
    "SELECT  (STR(?claims) as ?no_of_incoming_links) (COUNT(*) as ?no_of_rivers)  WITH {\n",
    "  SELECT distinct ?river WHERE {\n",
    "  #  VALUES ?river {wd:Q19721}\n",
    "   ?river wdt:P131/wdt:P131 wd:Q22 . \n",
    "    } } as %i\n",
    "WITH {\n",
    "  SELECT distinct ?river WHERE {\n",
    "    INCLUDE %i\n",
    "    ?river wdt:P31/wdt:P279* wd:Q55659167. hint:Prior hint:gearing \"forward\".\n",
    "    } } as %j\n",
    "WITH {\n",
    "  SELECT ?river (COUNT(*) as ?items) (count(distinct ?item) as ?claims) WHERE {\n",
    "    INCLUDE %j\n",
    "    OPTIONAL { ?item ?predicate ?river .\n",
    "    ?property wikibase:directClaim ?predicate . } \n",
    "    } group by ?river } as %k\n",
    "WHERE\n",
    "{\n",
    "  INCLUDE %k\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"[AUTO_LANGUAGE],en\". } \n",
    "} GROUP BY ?claims ORDER BY DESC(?claims)\n",
    "'''\n",
    "\n",
    "result = regex_parse(sq5)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clauses': 4, 'relations': 1, 'subjects': 1, 'predicates': 1, 'objects': 1, 'literals': 1}\n"
     ]
    }
   ],
   "source": [
    "sq6 = \"\"\"\n",
    "SELECT ?item ?itemLabel ?prop ?propLabel ?value WHERE {\n",
    "  VALUES ?pred { wdt:P1628 wdt:P2235 } .\n",
    "  ?item ?pred ?value .\n",
    "  ?prop wikibase:directClaim ?pred .\n",
    "  FILTER( STRSTARTS( STR(?value), \"http://www.w3.org/2006/vcard/ns\" ) ) .\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" } .\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "print(regex_parse(sq6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155\n",
      "168\n"
     ]
    }
   ],
   "source": [
    "with open('/home/oval/wikidata-dataset/new_dataset/dev_cleaned.json', \"r\") as f:\n",
    "    d = json.load(f)\n",
    "print(len(d))\n",
    "\n",
    "with open('/home/oval/wikidata-dataset/new_dataset/test_0615_4am_cleaned.json', \"r\") as f:\n",
    "    temp=json.load(f)\n",
    "    print(len(temp))\n",
    "    d += temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323\n",
      "defaultdict(<class 'int'>, {'clauses': 8.959752321981425, 'relations': 4.0588235294117645, 'subjects': 1.758513931888545, 'predicates': 3.5789473684210527, 'objects': 4.563467492260062, 'literals': 0.47678018575851394})\n"
     ]
    }
   ],
   "source": [
    "# for i, convo in enumerate(d):\n",
    "from collections import defaultdict\n",
    "\n",
    "meta_statistics = defaultdict(int)\n",
    "\n",
    "print(len(d))\n",
    "\n",
    "for i, convo in enumerate(d):\n",
    "    # query = convo['query']['sparql']\n",
    "    query = convo['sparql']\n",
    "    # if i % 250 == 0:\n",
    "    #     print(i)\n",
    "    out = regex_parse(query)\n",
    "    meta_statistics['clauses'] += out['clauses']\n",
    "    meta_statistics['relations'] += out['relations']\n",
    "    meta_statistics['subjects'] += out['subjects']\n",
    "    meta_statistics['predicates'] += out['predicates']\n",
    "    meta_statistics['objects'] += out['objects']\n",
    "    meta_statistics['literals'] += out['literals']\n",
    "    \n",
    "for key in ['clauses', 'relations', 'subjects', 'predicates', 'objects', 'literals']:\n",
    "    meta_statistics[key] = meta_statistics[key] / len(d)\n",
    "    \n",
    "    \n",
    "print(meta_statistics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
